{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.01):\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.01)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(self.num_layers - 1):\n",
    "            Z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            A = self.sigmoid(Z)\n",
    "            self.activations.append(A)\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, y):\n",
    "        m = y.shape[0]\n",
    "        deltas = [self.activations[-1] - y]\n",
    "        for i in range(self.num_layers - 2, 0, -1):\n",
    "            delta = np.dot(deltas[-1], self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            deltas.append(delta)\n",
    "        deltas.reverse()\n",
    "\n",
    "        for i in range(self.num_layers - 1):\n",
    "            dW = np.dot(self.activations[i].T, deltas[i]) / m\n",
    "            db = np.sum(deltas[i], axis=0, keepdims=True) / m\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X, y, epochs, X_val=None, y_val=None):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(y)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = self.compute_loss(y, output)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    val_output = self.forward(X_val)\n",
    "                    val_loss = self.compute_loss(y_val, val_output)\n",
    "                    print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        predictions = self.forward(X)\n",
    "        correct = np.sum(np.argmax(predictions, axis=1) == np.argmax(y, axis=1))\n",
    "        accuracy = correct / y.shape[0]\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, categories, image_size=(64, 64)):\n",
    "    X_data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        if folder not in categories:\n",
    "            print(f\"Skipping unknown category folder: {folder}\")\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            try:\n",
    "                image = Image.open(file_path).convert('L')\n",
    "                image = image.resize(image_size)\n",
    "                image_array = np.array(image) / 255.0\n",
    "                X_data.append(image_array.flatten())\n",
    "\n",
    "                label = np.zeros(len(categories))\n",
    "                label[categories.index(folder)] = 1\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return np.array(X_data), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4000, 4096)\n",
      "Training labels shape: (4000, 5)\n",
      "Test data shape: (1000, 4096)\n",
      "Test labels shape: (1000, 5)\n",
      "Epoch 0, Loss: 0.2539336526393231\n",
      "Epoch 100, Loss: 0.1245173131657908\n",
      "Epoch 200, Loss: 0.08581676736743264\n",
      "Epoch 300, Loss: 0.07021880254831078\n",
      "Epoch 400, Loss: 0.06050313309935417\n",
      "Epoch 500, Loss: 0.050223151819127836\n",
      "Epoch 600, Loss: 0.04124496376299186\n",
      "Epoch 700, Loss: 0.03486742923935077\n",
      "Epoch 800, Loss: 0.030518461062498642\n",
      "Epoch 900, Loss: 0.027378374153730317\n",
      "Test Accuracy: 92.90%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths to directories\n",
    "train_dir = \"Task 4.0/Train\"\n",
    "test_dir = \"Task 4.0/Test\"\n",
    "\n",
    "# Categories\n",
    "categories = [\"Jade\", \"James\", \"Jane\", \"Joel\", \"Jovi\"]\n",
    "\n",
    "# Load training and test data\n",
    "X_train, y_train = load_data(train_dir, categories)\n",
    "X_test, y_test = load_data(test_dir, categories)\n",
    "\n",
    "# Debugging output for dataset dimensions\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Neural network configuration\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = len(categories)\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize and train the neural network\n",
    "nn = NeuralNetwork(layer_sizes=[input_size,hidden_size, output_size], learning_rate=learning_rate)\n",
    "nn.train(X_train, y_train, epochs)\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = nn.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
